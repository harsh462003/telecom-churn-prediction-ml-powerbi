{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8575d63b",
   "metadata": {},
   "source": [
    "# 03 â€” Modeling & Evaluation\n",
    "\n",
    "Train baseline models and generate plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve,\n",
    "    precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "\n",
    "OUT = Path(\"..\") / \"outputs\"\n",
    "X_train, X_test, y_train, y_test = joblib.load(OUT / \"data_splits.joblib\")\n",
    "preprocessor = joblib.load(OUT / \"preprocessor.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title=\"Confusion Matrix\"):\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, [\"No\", \"Yes\"])\n",
    "    plt.yticks(tick_marks, [\"No\", \"Yes\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(y_true, y_proba, title=\"ROC Curve\"):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Random\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_pr_curve(y_true, y_proba, title=\"Precision-Recall Curve\"):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
    "    ap = average_precision_score(y_true, y_proba)\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, label=f\"AP = {ap:.4f}\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def run_model(model, model_name):\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)[:, 1] if hasattr(pipe, \"predict_proba\") else None\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"MODEL: {model_name}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1-score : {f1:.4f}\")\n",
    "    if auc is not None:\n",
    "        print(f\"ROC-AUC  : {auc:.4f}\")\n",
    "\n",
    "    plot_confusion_matrix(cm, title=f\"{model_name} - Confusion Matrix\")\n",
    "    if y_proba is not None:\n",
    "        plot_roc_curve(y_test, y_proba, title=f\"{model_name} - ROC Curve\")\n",
    "        plot_pr_curve(y_test, y_proba, title=f\"{model_name} - PR Curve\")\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except Exception:\n",
    "    !pip -q install xgboost\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "results = []\n",
    "\n",
    "results.append(run_model(LogisticRegression(max_iter=4000, class_weight=\"balanced\", random_state=42), \"Logistic Regression\"))\n",
    "results.append(run_model(DecisionTreeClassifier(random_state=42, class_weight=\"balanced\"), \"Decision Tree\"))\n",
    "results.append(run_model(RandomForestClassifier(n_estimators=400, random_state=42, class_weight=\"balanced\", n_jobs=-1), \"Random Forest\"))\n",
    "results.append(run_model(GradientBoostingClassifier(random_state=42), \"Gradient Boosting\"))\n",
    "\n",
    "neg = (y_train == 0).sum()\n",
    "pos = (y_train == 1).sum()\n",
    "spw = float(neg) / float(pos)\n",
    "\n",
    "results.append(run_model(XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=spw\n",
    "), \"XGBoost\"))\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"roc_auc\", ascending=False)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(OUT / \"model_metrics.csv\", index=False)\n",
    "print(\"Saved:\", OUT / \"model_metrics.csv\")\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(results_df[\"model\"], results_df[\"roc_auc\"])\n",
    "plt.title(\"Model Comparison - ROC-AUC\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"ROC-AUC\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(results_df[\"model\"], results_df[\"f1\"])\n",
    "plt.title(\"Model Comparison - F1 Score\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
